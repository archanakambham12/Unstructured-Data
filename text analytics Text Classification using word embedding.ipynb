{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=pd.read_csv('imdb_sentiment.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    386\n",
       "0    362\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_combined = \" \".join(reviews.review.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms = []\n",
    "fdist = {}\n",
    "all_terms = reviews_combined.split(\" \")\n",
    "for word in all_terms:\n",
    "    fdist[word] = fdist.get(word,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "stop_nltk = stopwords.words(\"english\")\n",
    "stop_updated = stop_nltk + [\"...\",\"..\",\"!!\"] +[\"phone\",\n",
    "                                          \"mobile\",\"lenovo\",\"k8\",\n",
    "                                               \"note\",\"amazon\",\"n't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_updated1 = [term for term in all_terms \\\n",
    "                    if term not in stop_updated \\\n",
    "and term not in list(punctuation) and len(term)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer_s = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_updated_stem = [ stemmer_s.stem(word) for word in reviews_updated1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_updated_lemm = [ lemm.lemmatize(word) for word in reviews_updated1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  clean_txt(sent):\n",
    "    tokens = word_tokenize(sent.lower())\n",
    "    stemmed = [stemmer_s.stem(term) for term in tokens \n",
    "               if term not in stop_updated and\n",
    "               term not in list(punctuation) and len(term) > 2] \n",
    "    res = \" \".join(stemmed)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['clean_review'] = reviews.review.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "      <td>slow-mov aimless movi distress drift young man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "      <td>sure lost flat charact audienc near half walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "      <td>attempt arti black white clever camera angl mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "      <td>littl music anyth speak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "      <td>best scene movi gerardo tri find song keep run...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  A very, very, very slow-moving, aimless movie ...          0   \n",
       "1  Not sure who was more lost - the flat characte...          0   \n",
       "2  Attempting artiness with black & white and cle...          0   \n",
       "3       Very little music or anything to speak of.            0   \n",
       "4  The best scene in the movie was when Gerardo i...          1   \n",
       "\n",
       "                                        clean_review  \n",
       "0     slow-mov aimless movi distress drift young man  \n",
       "1      sure lost flat charact audienc near half walk  \n",
       "2  attempt arti black white clever camera angl mo...  \n",
       "3                            littl music anyth speak  \n",
       "4  best scene movi gerardo tri find song keep run...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from string import punctuation\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#stop_nltk=stopwords.words(\"english\")\n",
    "#d=stop_nltk+[\"...\",\"..\",\"!!\"]+['would','could','told','subject']\n",
    "\n",
    "#def clean_txt(sent):\n",
    "    #tokens=word_tokenize(sent.lower())\n",
    "   # rev=[term for term in tokens if term not in d and term not in list(punctuation) and len(term)>2]\n",
    "    #res=\" \".join(rev)\n",
    "    #return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142660</td>\n",
       "      <td>0.123922</td>\n",
       "      <td>-0.145142</td>\n",
       "      <td>0.073232</td>\n",
       "      <td>-0.106445</td>\n",
       "      <td>-0.007273</td>\n",
       "      <td>-0.106486</td>\n",
       "      <td>-0.023753</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>0.036760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.065633</td>\n",
       "      <td>-0.089193</td>\n",
       "      <td>-0.128990</td>\n",
       "      <td>-0.094889</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>-0.044490</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.088338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065959</td>\n",
       "      <td>-0.009280</td>\n",
       "      <td>-0.025065</td>\n",
       "      <td>0.155579</td>\n",
       "      <td>-0.042419</td>\n",
       "      <td>-0.047282</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>-0.119019</td>\n",
       "      <td>0.115560</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055379</td>\n",
       "      <td>0.059530</td>\n",
       "      <td>-0.132243</td>\n",
       "      <td>0.024272</td>\n",
       "      <td>-0.048584</td>\n",
       "      <td>-0.047811</td>\n",
       "      <td>-0.057088</td>\n",
       "      <td>-0.063049</td>\n",
       "      <td>0.037214</td>\n",
       "      <td>-0.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110306</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.051640</td>\n",
       "      <td>-0.088618</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.049298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025678</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>-0.117480</td>\n",
       "      <td>0.011088</td>\n",
       "      <td>-0.096287</td>\n",
       "      <td>-0.023344</td>\n",
       "      <td>-0.009563</td>\n",
       "      <td>-0.034526</td>\n",
       "      <td>-0.009094</td>\n",
       "      <td>-0.017124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002197</td>\n",
       "      <td>-0.085286</td>\n",
       "      <td>-0.022542</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>-0.025187</td>\n",
       "      <td>0.077962</td>\n",
       "      <td>0.055176</td>\n",
       "      <td>-0.128011</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>-0.040202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066650</td>\n",
       "      <td>0.088216</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>-0.019450</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>-0.042643</td>\n",
       "      <td>0.042643</td>\n",
       "      <td>-0.033122</td>\n",
       "      <td>0.123830</td>\n",
       "      <td>-0.012939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.044481</td>\n",
       "      <td>-0.052585</td>\n",
       "      <td>-0.027764</td>\n",
       "      <td>-0.032145</td>\n",
       "      <td>-0.073251</td>\n",
       "      <td>0.070543</td>\n",
       "      <td>-0.001460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012163</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>-0.100895</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>-0.022108</td>\n",
       "      <td>-0.079359</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>-0.069292</td>\n",
       "      <td>0.014838</td>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.142660  0.123922 -0.145142  0.073232 -0.106445 -0.007273 -0.106486   \n",
       "1  0.065959 -0.009280 -0.025065  0.155579 -0.042419 -0.047282  0.006429   \n",
       "2  0.110306  0.027736  0.005709  0.051640 -0.088618 -0.001378  0.034108   \n",
       "3 -0.002197 -0.085286 -0.022542  0.060818 -0.025187  0.077962  0.055176   \n",
       "4  0.002970  0.004822  0.009481  0.044481 -0.052585 -0.027764 -0.032145   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.023753  0.012431  0.036760  ...  0.033691  0.065633 -0.089193 -0.128990   \n",
       "1 -0.119019  0.115560  0.089111  ... -0.055379  0.059530 -0.132243  0.024272   \n",
       "2  0.009286  0.000392  0.049298  ... -0.025678  0.041327 -0.117480  0.011088   \n",
       "3 -0.128011  0.008138 -0.040202  ...  0.066650  0.088216 -0.051270 -0.019450   \n",
       "4 -0.073251  0.070543 -0.001460  ... -0.012163  0.067600 -0.100895  0.000629   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.094889  0.037313  0.005534 -0.044490  0.041667  0.088338  \n",
       "1 -0.048584 -0.047811 -0.057088 -0.063049  0.037214 -0.136800  \n",
       "2 -0.096287 -0.023344 -0.009563 -0.034526 -0.009094 -0.017124  \n",
       "3  0.040283 -0.042643  0.042643 -0.033122  0.123830 -0.012939  \n",
       "4 -0.022108 -0.079359  0.015357 -0.069292  0.014838  0.010417  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_vectors=pd.DataFrame()\n",
    "for doc in reviews.clean_review:\n",
    "    temp=pd.DataFrame()\n",
    "    words=doc.split(' ')\n",
    "    #print(words)\n",
    "    for word in words:\n",
    "        try:\n",
    "            word2vec=embeddings[word]   ## gives vector of length\n",
    "            temp=temp.append(pd.Series(word2vec),ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "    doc_vector=temp.mean()\n",
    "    docs_vectors=docs_vectors.append(doc_vector,ignore_index=True)\n",
    "docs_vectors.head()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_model='GoogleNews-vectors-negative300.bin'\n",
    "embeddings=gensim.models.KeyedVectors.load_word2vec_format(google_model,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectors=docs_vectors.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = docs_vectors\n",
    "y = reviews.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train,y_test = \\\n",
    "train_test_split(X,y,test_size=0.25,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839572192513369"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
